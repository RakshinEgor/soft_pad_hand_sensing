{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c5d6367",
   "metadata": {},
   "source": [
    "# 1. Camera check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01147153",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyrealsense2 as rs\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "# Создаём конвейер\n",
    "pipe = rs.pipeline()\n",
    "cfg = rs.config()\n",
    "cfg.enable_stream(rs.stream.color, 1920, 1080, rs.format.bgr8, 30)\n",
    "\n",
    "# Запускаем\n",
    "profile = pipe.start(cfg)\n",
    "\n",
    "# Получаем настройки цветного сенсора\n",
    "color_sensor = profile.get_device().query_sensors()[1]  # 0 — depth, 1 — color\n",
    "\n",
    "# Включаем автоэкспозицию и автокоррекцию баланса белого\n",
    "color_sensor.set_option(rs.option.enable_auto_exposure, True)\n",
    "color_sensor.set_option(rs.option.enable_auto_white_balance, True)\n",
    "\n",
    "# Можно слегка увеличить экспозицию вручную (по желанию)\n",
    "# color_sensor.set_option(rs.option.exposure, 200)  # мс\n",
    "# color_sensor.set_option(rs.option.gain, 32)      # усиление\n",
    "\n",
    "# Настраиваем сглаживание\n",
    "fps_counter, t0 = 0, time.time()\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        frames = pipe.wait_for_frames()\n",
    "        color_frame = frames.get_color_frame()\n",
    "        if not color_frame:\n",
    "            continue\n",
    "\n",
    "        # Получаем numpy-кадр\n",
    "        color_image = np.asanyarray(color_frame.get_data())\n",
    "\n",
    "        # Лёгкое сглаживание для шумоподавления (уменьшает зерно)\n",
    "        color_image = cv2.bilateralFilter(color_image, 5, 50, 50)\n",
    "\n",
    "        # Считаем FPS\n",
    "        fps_counter += 1\n",
    "        if time.time() - t0 >= 1.0:\n",
    "            fps = fps_counter\n",
    "            fps_counter, t0 = 0, time.time()\n",
    "        else:\n",
    "            fps = None\n",
    "\n",
    "        # Добавляем текст с FPS\n",
    "        if fps is not None:\n",
    "            cv2.putText(color_image, f\"FPS: {fps}\", (10, 30),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "        # Отображаем\n",
    "        cv2.imshow(\"RGB 1920x1080 (smoothed)\", color_image)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "finally:\n",
    "    pipe.stop()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76795f08",
   "metadata": {},
   "source": [
    "# 2. Blue mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb0b6838",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyrealsense2 as rs\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# --- Настройка камеры (только RGB 1920x1080) ---\n",
    "pipe = rs.pipeline()\n",
    "cfg = rs.config()\n",
    "cfg.enable_stream(rs.stream.color, 1920, 1080, rs.format.bgr8, 30)\n",
    "pipe.start(cfg)\n",
    "\n",
    "# --- Диапазон синего в HSV (смягчённый) ---\n",
    "lower_blue = np.array([95, 60, 40])\n",
    "upper_blue = np.array([145, 255, 255])\n",
    "\n",
    "# Структурный элемент для морфологии\n",
    "kernel = np.ones((7, 7), np.uint8)\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        frames = pipe.wait_for_frames()\n",
    "        color_frame = frames.get_color_frame()\n",
    "        if not color_frame:\n",
    "            continue\n",
    "\n",
    "        # RGB-кадр\n",
    "        color_image = np.asanyarray(color_frame.get_data())\n",
    "\n",
    "        # 1️⃣ Гауссово размытие\n",
    "        blurred = cv2.GaussianBlur(color_image, (9, 9), 0)\n",
    "\n",
    "        # 2️⃣ HSV и маска\n",
    "        hsv = cv2.cvtColor(blurred, cv2.COLOR_BGR2HSV)\n",
    "        mask = cv2.inRange(hsv, lower_blue, upper_blue)\n",
    "\n",
    "        # 3️⃣ Морфология: закрытие + открытие\n",
    "        mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "        # 4️⃣ Поиск связных областей\n",
    "        num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(mask, connectivity=8)\n",
    "\n",
    "        if num_labels > 1:\n",
    "            # Индекс самой большой области (кроме фона)\n",
    "            largest = 1 + np.argmax(stats[1:, cv2.CC_STAT_AREA])\n",
    "            x, y, w, h, area = stats[largest]\n",
    "            cx, cy = map(int, centroids[largest])\n",
    "\n",
    "            # Создаём маску только для этой области\n",
    "            mask = np.where(labels == largest, 255, 0).astype(np.uint8)\n",
    "\n",
    "            # Визуализация\n",
    "            cv2.rectangle(color_image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "            cv2.circle(color_image, (cx, cy), 5, (0, 0, 255), -1)\n",
    "            cv2.putText(color_image, f\"Blue FinRay\", (x, y - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "\n",
    "        # 5️⃣ Объединяем для визуализации\n",
    "        mask_colored = cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR)\n",
    "        result = cv2.bitwise_and(color_image, mask_colored)\n",
    "        stacked = np.hstack((color_image, result))\n",
    "\n",
    "        cv2.imshow(\"RGB | Masked\", cv2.resize(stacked, (1280, 480)))\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "finally:\n",
    "    pipe.stop()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c2968b",
   "metadata": {},
   "source": [
    "# 3. Better mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2dec306c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] picked HSV=(2, 234, 123) at panel 0, pixel (506,486)\n",
      "[INFO] picked HSV=(72, 224, 108) at panel 0, pixel (594,254)\n",
      "[INFO] picked HSV=(101, 255, 127) at panel 0, pixel (244,238)\n",
      "[INFO] picked HSV=(0, 239, 157) at panel 0, pixel (506,344)\n",
      "[INFO] picked HSV=(100, 232, 147) at panel 0, pixel (334,572)\n",
      "[INFO] picked HSV=(1, 238, 162) at panel 0, pixel (496,342)\n",
      "[INFO] picked HSV=(72, 173, 121) at panel 0, pixel (690,182)\n",
      "[INFO] picked HSV=(100, 199, 122) at panel 0, pixel (350,218)\n",
      "[INFO] picked HSV=(173, 8, 129) at panel 0, pixel (224,202)\n",
      "[INFO] picked HSV=(102, 255, 118) at panel 0, pixel (234,480)\n",
      "[INFO] picked HSV=(3, 201, 185) at panel 0, pixel (452,330)\n",
      "[INFO] picked HSV=(70, 223, 103) at panel 0, pixel (588,262)\n",
      "[INFO] picked HSV=(166, 174, 98) at panel 0, pixel (506,318)\n",
      "[INFO] picked HSV=(100, 139, 66) at panel 0, pixel (922,620)\n",
      "[INFO] picked HSV=(73, 243, 104) at panel 0, pixel (730,384)\n",
      "[INFO] picked HSV=(71, 222, 107) at panel 0, pixel (544,224)\n",
      "[INFO] picked HSV=(15, 255, 250) at panel 0, pixel (432,398)\n",
      "[INFO] picked HSV=(63, 255, 174) at panel 0, pixel (564,282)\n",
      "[INFO] picked HSV=(91, 255, 251) at panel 0, pixel (216,418)\n",
      "[INFO] picked HSV=(15, 255, 255) at panel 0, pixel (432,418)\n",
      "[INFO] picked HSV=(64, 255, 175) at panel 0, pixel (558,276)\n",
      "[INFO] picked HSV=(17, 255, 244) at panel 0, pixel (430,418)\n",
      "[INFO] picked HSV=(64, 255, 168) at panel 0, pixel (566,298)\n",
      "[INFO] picked HSV=(65, 230, 103) at panel 0, pixel (566,290)\n",
      "[INFO] picked HSV=(2, 244, 158) at panel 0, pixel (424,418)\n",
      "[INFO] picked HSV=(3, 228, 170) at panel 0, pixel (424,404)\n",
      "[INFO] picked HSV=(73, 253, 102) at panel 0, pixel (596,310)\n"
     ]
    }
   ],
   "source": [
    "import pyrealsense2 as rs\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "# ---------------- Config ----------------\n",
    "CAM_W, CAM_H = 1280, 720      # capture resolution (HD)\n",
    "PROC_W, PROC_H = 640, 360     # processing resolution (smaller = faster)\n",
    "\n",
    "H_TOL = 20\n",
    "S_TOL = 80\n",
    "V_TOL = 80\n",
    "\n",
    "MIN_AREA_PROC = 300\n",
    "\n",
    "K_CLOSE = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (9, 9))\n",
    "K_OPEN  = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "K_SMALL = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "\n",
    "# ---------------- Helpers ----------------\n",
    "def make_hue_mask_wrap(hsv, low_h, high_h, low_s, high_s, low_v, high_v):\n",
    "    lh = int(round(low_h)) % 180\n",
    "    hh = int(round(high_h)) % 180\n",
    "    ls = int(max(0, low_s)); hs = int(min(255, high_s))\n",
    "    lv = int(max(0, low_v)); hv = int(min(255, high_v))\n",
    "    if lh <= hh:\n",
    "        return cv2.inRange(hsv, (lh, ls, lv), (hh, hs, hv))\n",
    "    else:\n",
    "        m1 = cv2.inRange(hsv, (lh, ls, lv), (179, hs, hv))\n",
    "        m2 = cv2.inRange(hsv, (0, ls, lv), (hh, hs, hv))\n",
    "        return cv2.bitwise_or(m1, m2)\n",
    "\n",
    "def smooth_contour(contour, ksize=21, sigma=7):\n",
    "    pts = contour.reshape(-1, 2).astype(np.float32)\n",
    "    N = len(pts)\n",
    "    if N < 6:\n",
    "        return contour.astype(np.int32)\n",
    "    pad = ksize // 2\n",
    "    pts_padded = np.vstack([pts[-pad:], pts, pts[:pad]])\n",
    "    gk = cv2.getGaussianKernel(ksize, sigma).flatten()\n",
    "    gk /= gk.sum()\n",
    "    xs = np.convolve(pts_padded[:,0], gk, mode='valid')\n",
    "    ys = np.convolve(pts_padded[:,1], gk, mode='valid')\n",
    "    sm = np.vstack([xs, ys]).T.astype(np.int32)\n",
    "    return sm.reshape(-1,1,2)\n",
    "\n",
    "# ---------------- Globals for mouse mapping ----------------\n",
    "selected_hsv = None\n",
    "color_selected = False\n",
    "hsv_full = None          # updated each loop\n",
    "# combined/display sizes used to map click coords -> full image coords\n",
    "_combined_w = None\n",
    "_combined_h = None\n",
    "_display_w = None\n",
    "_display_h = None\n",
    "\n",
    "def on_mouse(event, x, y, flags, param):\n",
    "    global selected_hsv, color_selected, hsv_full, _combined_w, _combined_h, _display_w, _display_h\n",
    "    if event != cv2.EVENT_LBUTTONDOWN:\n",
    "        return\n",
    "    if hsv_full is None or _combined_w is None or _display_w is None:\n",
    "        return\n",
    "    # map click (x,y) from displayed (resized) image -> combined image coords\n",
    "    # x_display in [0,_display_w) -> x_combined in [0,_combined_w)\n",
    "    x_comb = int(x * (_combined_w / _display_w))\n",
    "    y_comb = int(y * (_combined_h / _display_h))\n",
    "    # determine which panel (0:left raw, 1:middle bbox, 2:right color_only)\n",
    "    panel_idx = x_comb // CAM_W\n",
    "    x_in_panel = x_comb % CAM_W\n",
    "    y_in_panel = y_comb\n",
    "    # clamp\n",
    "    if x_in_panel < 0 or x_in_panel >= CAM_W or y_in_panel < 0 or y_in_panel >= CAM_H:\n",
    "        return\n",
    "    # read HSV from full-res hsv_full at that location\n",
    "    h,s,v = hsv_full[y_in_panel, x_in_panel]\n",
    "    selected_hsv = (int(h), int(s), int(v))\n",
    "    color_selected = True\n",
    "    print(f\"[INFO] picked HSV={selected_hsv} at panel {panel_idx}, pixel ({x_in_panel},{y_in_panel})\")\n",
    "\n",
    "# ---------------- Camera init ----------------\n",
    "pipe = rs.pipeline()\n",
    "cfg = rs.config()\n",
    "cfg.enable_stream(rs.stream.color, CAM_W, CAM_H, rs.format.bgr8, 30)\n",
    "profile = pipe.start(cfg)\n",
    "\n",
    "WINDOW = \"Color Picker - Click to pick color | Q to quit\"\n",
    "cv2.namedWindow(WINDOW, cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow(WINDOW, 1920, 720)\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        frames = pipe.wait_for_frames()\n",
    "        color_frame = frames.get_color_frame()\n",
    "        if not color_frame:\n",
    "            continue\n",
    "\n",
    "        full = np.asanyarray(color_frame.get_data())  # CAM_H x CAM_W x 3\n",
    "        # make hsv_full for picking color\n",
    "        hsv_full = cv2.cvtColor(full, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "        # small copy for processing\n",
    "        small = cv2.resize(full, (PROC_W, PROC_H), interpolation=cv2.INTER_LINEAR)\n",
    "        blur = cv2.GaussianBlur(small, (5,5), 0)\n",
    "        hsv_small = cv2.cvtColor(blur, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "        raw_view = full.copy()\n",
    "        bbox_view = full.copy()\n",
    "        color_only = np.zeros_like(full)\n",
    "\n",
    "        if color_selected and selected_hsv is not None:\n",
    "            h0, s0, v0 = selected_hsv\n",
    "            h_low, h_high = h0 - H_TOL, h0 + H_TOL\n",
    "            s_low, s_high = s0 - S_TOL, s0 + S_TOL\n",
    "            v_low, v_high = v0 - V_TOL, v0 + V_TOL\n",
    "\n",
    "            mask_small = make_hue_mask_wrap(hsv_small, h_low, h_high, s_low, s_high, v_low, v_high)\n",
    "            mask_small = cv2.morphologyEx(mask_small, cv2.MORPH_CLOSE, K_CLOSE, iterations=1)\n",
    "            mask_small = cv2.morphologyEx(mask_small, cv2.MORPH_OPEN, K_OPEN, iterations=1)\n",
    "            mask_small = cv2.medianBlur(mask_small, 5)\n",
    "\n",
    "            # keep holes: find hierarchy and fill external contours, subtract holes\n",
    "            contours, hierarchy = cv2.findContours(mask_small, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_NONE)\n",
    "            mask_final_small = np.zeros_like(mask_small)\n",
    "            if contours and hierarchy is not None:\n",
    "                hierarchy = hierarchy[0]\n",
    "                # choose largest external component by filled area (external contours have parent == -1)\n",
    "                external_idxs = [i for i in range(len(contours)) if hierarchy[i][3] == -1]\n",
    "                if len(external_idxs) == 0:\n",
    "                    # fallback: take the largest contour overall\n",
    "                    idx_largest = int(np.argmax([cv2.contourArea(c) for c in contours]))\n",
    "                    external_idxs = [idx_largest]\n",
    "                # pick the largest external\n",
    "                ext_areas = [(i, cv2.contourArea(contours[i])) for i in external_idxs]\n",
    "                best_ext = max(ext_areas, key=lambda x: x[1])[0]\n",
    "                # collect children (holes) recursively\n",
    "                comp_indices = [best_ext]\n",
    "                # BFS downwards to collect all descendants of best_ext\n",
    "                q = [best_ext]\n",
    "                while q:\n",
    "                    p = q.pop(0)\n",
    "                    for i in range(len(contours)):\n",
    "                        if hierarchy[i][3] == p:\n",
    "                            comp_indices.append(i)\n",
    "                            q.append(i)\n",
    "                # fill external contour (smoothed)\n",
    "                outer_contour = contours[best_ext]\n",
    "                outer_s = smooth_contour(outer_contour, ksize=21, sigma=7)\n",
    "                cv2.fillPoly(mask_final_small, [outer_s], 255)\n",
    "                # subtract holes (children in comp_indices except the outer itself)\n",
    "                for idx in comp_indices:\n",
    "                    if idx == best_ext:\n",
    "                        continue\n",
    "                    hole = contours[idx]\n",
    "                    hole_s = smooth_contour(hole, ksize=21, sigma=7)\n",
    "                    cv2.fillPoly(mask_final_small, [hole_s], 0)\n",
    "\n",
    "            # remove tiny islands but preserve holes: small opening\n",
    "            mask_final_small = cv2.morphologyEx(mask_final_small, cv2.MORPH_OPEN, K_SMALL, iterations=1)\n",
    "\n",
    "            # scale mask up to full resolution using nearest to preserve holes\n",
    "            mask_full = cv2.resize(mask_final_small, (CAM_W, CAM_H), interpolation=cv2.INTER_NEAREST)\n",
    "            mask_full = (mask_full > 127).astype(np.uint8) * 255\n",
    "\n",
    "            # find largest contour at full size for bbox/centroid\n",
    "            cnts_full, _ = cv2.findContours(mask_full, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            if cnts_full:\n",
    "                c_full = max(cnts_full, key=cv2.contourArea)\n",
    "                area_full = cv2.contourArea(c_full)\n",
    "                if area_full > 0:\n",
    "                    x,y,w,h = cv2.boundingRect(c_full)\n",
    "                    M = cv2.moments(c_full)\n",
    "                    if M[\"m00\"] != 0:\n",
    "                        cx = int(M[\"m10\"]/M[\"m00\"]); cy = int(M[\"m01\"]/M[\"m00\"])\n",
    "                    else:\n",
    "                        cx,cy = x + w//2, y + h//2\n",
    "                    cv2.drawContours(bbox_view, [c_full], -1, (0,255,255), 2)\n",
    "                    cv2.rectangle(bbox_view, (x,y), (x+w, y+h), (0,255,0), 3)\n",
    "                    cv2.circle(bbox_view, (cx,cy), 6, (0,0,255), -1)\n",
    "                    cv2.putText(bbox_view, f\"HSV={selected_hsv}\", (x, max(30, y-10)),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,255,255), 2, cv2.LINE_AA)\n",
    "                    color_only = cv2.bitwise_and(full, full, mask=mask_full)\n",
    "\n",
    "        # combine three panels side-by-side (preserve original aspect ratio of each panel)\n",
    "        combined = np.hstack([raw_view, bbox_view, color_only])  # width = 3*CAM_W, height = CAM_H\n",
    "        _combined_h, _combined_w = combined.shape[0], combined.shape[1]\n",
    "\n",
    "        # scale to fit large window height 720 while keeping aspect ratio\n",
    "        target_h = 720\n",
    "        scale = target_h / _combined_h\n",
    "        display_w = int(_combined_w * scale)\n",
    "        display_h = target_h\n",
    "        display = cv2.resize(combined, (display_w, display_h), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "        # update mapping globals before showing (used by mouse handler)\n",
    "        _display_w, _display_h = display_w, display_h\n",
    "\n",
    "        hint = \"Click (LMB) any pixel on camera to pick color | Q to quit\"\n",
    "        if color_selected and selected_hsv is not None:\n",
    "            hint = f\"{hint}    Selected HSV={selected_hsv}\"\n",
    "        cv2.putText(display, hint, (10,30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,255,255), 2, cv2.LINE_AA)\n",
    "\n",
    "        cv2.imshow(WINDOW, display)\n",
    "        cv2.setMouseCallback(WINDOW, on_mouse)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "finally:\n",
    "    pipe.stop()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5366084",
   "metadata": {},
   "source": [
    "# 4. Point cloud fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4cf0c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Selected HSV=(71, 240, 102) at (392,378) panel=1\n",
      "[INFO] Initialized 20 points.\n",
      "[INFO] Selected HSV=(72, 201, 123) at (350,332) panel=1\n",
      "[INFO] Initialized 574 points.\n",
      "[INFO] Selected HSV=(71, 213, 121) at (277,336) panel=1\n",
      "[INFO] Initialized 1485 points.\n",
      "[INFO] Selected HSV=(73, 220, 115) at (404,353) panel=1\n",
      "[INFO] Initialized 5000 points.\n"
     ]
    }
   ],
   "source": [
    "import pyrealsense2 as rs\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "# ---------------- Config ----------------\n",
    "CAM_W, CAM_H = 1280, 720      # capture resolution (HD)\n",
    "PROC_W, PROC_H = 640, 360     # processing resolution (smaller = faster)\n",
    "\n",
    "# HSV tolerance (around picked HSV)\n",
    "H_TOL = 18\n",
    "S_TOL = 80\n",
    "V_TOL = 80\n",
    "\n",
    "MIN_AREA_PROC = 300\n",
    "SAMPLE_COUNT = 20             # default sample count (trackbar controls)\n",
    "\n",
    "# Morphology\n",
    "K_CLOSE = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (9, 9))\n",
    "K_OPEN  = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "K_SMALL = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "\n",
    "# ---------------- Drift/stability params ----------------\n",
    "# If median motion is below this (in pixels), treat as jitter and don't snap fully.\n",
    "JITTER_THRESH_PX = 1.0   # pixels\n",
    "# Exponential smoothing for small jitter vs real motion\n",
    "EMA_ALPHA_MOVING = 0.99   # when real motion — respond fairly quickly\n",
    "EMA_ALPHA_STATIC = 0.1  # when static / jitter — update slowly\n",
    "# When applying registration fallback (affine), blend with this weight\n",
    "REG_ALPHA = 0.6\n",
    "\n",
    "# optical flow params\n",
    "LK_WIN = (21, 21)\n",
    "LK_MAXLEVEL = 3\n",
    "LK_CRITERIA = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 30, 0.01)\n",
    "\n",
    "# RNG\n",
    "rng = np.random.default_rng()\n",
    "\n",
    "# ---------------- Helpers ----------------\n",
    "def make_hue_mask_wrap(hsv, low_h, high_h, low_s, high_s, low_v, high_v):\n",
    "    lh = int(round(low_h)) % 180\n",
    "    hh = int(round(high_h)) % 180\n",
    "    ls = int(max(0, low_s)); hs = int(min(255, high_s))\n",
    "    lv = int(max(0, low_v)); hv = int(min(255, high_v))\n",
    "    if lh <= hh:\n",
    "        return cv2.inRange(hsv, (lh, ls, lv), (hh, hs, hv))\n",
    "    else:\n",
    "        m1 = cv2.inRange(hsv, (lh, ls, lv), (179, hs, hv))\n",
    "        m2 = cv2.inRange(hsv, (0, ls, lv), (hh, hs, hv))\n",
    "        return cv2.bitwise_or(m1, m2)\n",
    "\n",
    "def smooth_contour(contour, ksize=21, sigma=7):\n",
    "    pts = contour.reshape(-1, 2).astype(np.float32)\n",
    "    N = len(pts)\n",
    "    if N < 6:\n",
    "        return contour.astype(np.int32)\n",
    "    pad = ksize // 2\n",
    "    pts_padded = np.vstack([pts[-pad:], pts, pts[:pad]])\n",
    "    gk = cv2.getGaussianKernel(ksize, sigma).flatten()\n",
    "    gk /= gk.sum()\n",
    "    xs = np.convolve(pts_padded[:,0], gk, mode='valid')\n",
    "    ys = np.convolve(pts_padded[:,1], gk, mode='valid')\n",
    "    sm = np.vstack([xs, ys]).T.astype(np.int32)\n",
    "    return sm.reshape(-1,1,2)\n",
    "\n",
    "# ---------------- Globals for UI / tracking ----------------\n",
    "selected_hsv = None\n",
    "color_selected = False\n",
    "hsv_full = None\n",
    "\n",
    "sampled_points = None            # Nx2 float32 (full-res coordinates)\n",
    "sampled_points_initial = None\n",
    "prev_gray = None\n",
    "_tracking_initialized = False\n",
    "\n",
    "# gui mapping globals\n",
    "_combined_w = None\n",
    "_combined_h = None\n",
    "_display_w = None\n",
    "_display_h = None\n",
    "\n",
    "# ---------------- Mouse callback ----------------\n",
    "def on_mouse(event, x, y, flags, param):\n",
    "    global selected_hsv, color_selected, hsv_full\n",
    "    global sampled_points, sampled_points_initial, _tracking_initialized\n",
    "    global _combined_w, _combined_h, _display_w, _display_h\n",
    "    if event != cv2.EVENT_LBUTTONDOWN:\n",
    "        return\n",
    "    if hsv_full is None or _combined_w is None or _display_w is None or _display_w == 0:\n",
    "        return\n",
    "    # Map click from displayed coords -> combined coords\n",
    "    x_comb = int(x * (_combined_w / _display_w))\n",
    "    y_comb = int(y * (_combined_h / _display_h))\n",
    "    # Panel index (left raw panel is panel 0)\n",
    "    panel_idx = x_comb // CAM_W\n",
    "    x_in_panel = x_comb % CAM_W\n",
    "    y_in_panel = y_comb\n",
    "    # clamp\n",
    "    if not (0 <= x_in_panel < CAM_W and 0 <= y_in_panel < CAM_H):\n",
    "        return\n",
    "    h,s,v = hsv_full[y_in_panel, x_in_panel]\n",
    "    selected_hsv = (int(h), int(s), int(v))\n",
    "    color_selected = True\n",
    "    # force regeneration of points on click\n",
    "    _tracking_initialized = False\n",
    "    sampled_points = None\n",
    "    sampled_points_initial = None\n",
    "    print(f\"[INFO] Selected HSV={selected_hsv} at ({x_in_panel},{y_in_panel}) panel={panel_idx}\")\n",
    "\n",
    "# ---------------- Trackbar callback ----------------\n",
    "def on_trackbar(val):\n",
    "    # no immediate re-generation; regeneration happens on next click\n",
    "    pass\n",
    "\n",
    "# ---------------- Camera init & GUI ----------------\n",
    "pipe = rs.pipeline()\n",
    "cfg = rs.config()\n",
    "cfg.enable_stream(rs.stream.color, CAM_W, CAM_H, rs.format.bgr8, 30)\n",
    "profile = pipe.start(cfg)\n",
    "\n",
    "WINDOW = \"Color Tracker + Stable Points (click to pick color) | Q to quit\"\n",
    "cv2.namedWindow(WINDOW, cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow(WINDOW, 1920, 720)\n",
    "cv2.setMouseCallback(WINDOW, on_mouse)\n",
    "\n",
    "# create trackbar for sample count\n",
    "cv2.createTrackbar(\"NumPoints\", WINDOW, SAMPLE_COUNT, 5000, on_trackbar)\n",
    "\n",
    "# ---------------- Main loop ----------------\n",
    "try:\n",
    "    while True:\n",
    "        frames = pipe.wait_for_frames()\n",
    "        color_frame = frames.get_color_frame()\n",
    "        if not color_frame:\n",
    "            continue\n",
    "\n",
    "        full = np.asanyarray(color_frame.get_data())  # CAM_H x CAM_W x 3\n",
    "        hsv_full = cv2.cvtColor(full, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "        # small copy for processing\n",
    "        small = cv2.resize(full, (PROC_W, PROC_H), interpolation=cv2.INTER_LINEAR)\n",
    "        blur = cv2.GaussianBlur(small, (5,5), 0)\n",
    "        hsv_small = cv2.cvtColor(blur, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "        raw_view = full.copy()\n",
    "        bbox_view = full.copy()\n",
    "        color_only = np.zeros_like(full)\n",
    "\n",
    "        # read SAMPLE_COUNT from trackbar (it won't regenerate points until next click)\n",
    "        SAMPLE_COUNT = cv2.getTrackbarPos(\"NumPoints\", WINDOW)\n",
    "\n",
    "        if color_selected and selected_hsv is not None:\n",
    "            h0, s0, v0 = selected_hsv\n",
    "            h_low, h_high = h0 - H_TOL, h0 + H_TOL\n",
    "            s_low, s_high = s0 - S_TOL, s0 + S_TOL\n",
    "            v_low, v_high = v0 - V_TOL, v0 + V_TOL\n",
    "\n",
    "            # small mask\n",
    "            mask_small = make_hue_mask_wrap(hsv_small, h_low, h_high, s_low, s_high, v_low, v_high)\n",
    "            mask_small = cv2.morphologyEx(mask_small, cv2.MORPH_CLOSE, K_CLOSE, iterations=1)\n",
    "            mask_small = cv2.morphologyEx(mask_small, cv2.MORPH_OPEN, K_OPEN, iterations=1)\n",
    "            mask_small = cv2.medianBlur(mask_small, 5)\n",
    "\n",
    "            # preserve holes: pick largest external component and subtract holes\n",
    "            contours, hierarchy = cv2.findContours(mask_small, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_NONE)\n",
    "            mask_final_small = np.zeros_like(mask_small)\n",
    "            if contours and hierarchy is not None:\n",
    "                hierarchy = hierarchy[0]\n",
    "                external_idxs = [i for i in range(len(contours)) if hierarchy[i][3] == -1]\n",
    "                if len(external_idxs) == 0:\n",
    "                    idx_largest = int(np.argmax([cv2.contourArea(c) for c in contours]))\n",
    "                    external_idxs = [idx_largest]\n",
    "                ext_areas = [(i, cv2.contourArea(contours[i])) for i in external_idxs]\n",
    "                best_ext = max(ext_areas, key=lambda x: x[1])[0]\n",
    "\n",
    "                # collect descendants\n",
    "                comp_indices = [best_ext]\n",
    "                q = [best_ext]\n",
    "                while q:\n",
    "                    p = q.pop(0)\n",
    "                    for i in range(len(contours)):\n",
    "                        if hierarchy[i][3] == p:\n",
    "                            comp_indices.append(i)\n",
    "                            q.append(i)\n",
    "\n",
    "                outer_contour = contours[best_ext]\n",
    "                outer_s = smooth_contour(outer_contour, ksize=21, sigma=7)\n",
    "                cv2.fillPoly(mask_final_small, [outer_s], 255)\n",
    "\n",
    "                for idx in comp_indices:\n",
    "                    if idx == best_ext:\n",
    "                        continue\n",
    "                    hole = contours[idx]\n",
    "                    hole_s = smooth_contour(hole, ksize=21, sigma=7)\n",
    "                    cv2.fillPoly(mask_final_small, [hole_s], 0)\n",
    "\n",
    "            mask_final_small = cv2.morphologyEx(mask_final_small, cv2.MORPH_OPEN, K_SMALL, iterations=1)\n",
    "\n",
    "            # upscale mask\n",
    "            mask_full = cv2.resize(mask_final_small, (CAM_W, CAM_H), interpolation=cv2.INTER_NEAREST)\n",
    "            mask_full = (mask_full > 127).astype(np.uint8) * 255\n",
    "\n",
    "            # initialize sampled_points on click (only once until next click)\n",
    "            if (not _tracking_initialized) and np.any(mask_full > 0):\n",
    "                ys, xs = np.where(mask_full > 0)\n",
    "                if len(xs) > 0 and SAMPLE_COUNT > 0:\n",
    "                    count = min(SAMPLE_COUNT, len(xs))\n",
    "                    replace = False if count <= len(xs) else True\n",
    "                    idxs = rng.choice(len(xs), size=count, replace=replace)\n",
    "                    pts = np.column_stack([xs[idxs], ys[idxs]]).astype(np.float32)\n",
    "                    sampled_points = pts.copy()\n",
    "                    sampled_points_initial = pts.copy()\n",
    "                else:\n",
    "                    sampled_points = np.zeros((0,2), dtype=np.float32)\n",
    "                    sampled_points_initial = sampled_points.copy()\n",
    "                prev_gray = cv2.cvtColor(full, cv2.COLOR_BGR2GRAY)\n",
    "                _tracking_initialized = True\n",
    "                print(f\"[INFO] Initialized {len(sampled_points)} points.\")\n",
    "\n",
    "            # If points exist, track them with LK + stability filtering\n",
    "            if _tracking_initialized and sampled_points is not None and sampled_points.shape[0] > 0:\n",
    "                curr_gray = cv2.cvtColor(full, cv2.COLOR_BGR2GRAY)\n",
    "                p0 = sampled_points.reshape(-1,1,2).astype(np.float32)\n",
    "                p1, st, err = cv2.calcOpticalFlowPyrLK(prev_gray, curr_gray, p0, None,\n",
    "                                                       winSize=LK_WIN, maxLevel=LK_MAXLEVEL,\n",
    "                                                       criteria=LK_CRITERIA)\n",
    "                if p1 is not None:\n",
    "                    st = st.reshape(-1)\n",
    "                    good_idx = np.where(st==1)[0]\n",
    "                    if good_idx.size > 0:\n",
    "                        # motion vectors only for successfully tracked points\n",
    "                        deltas = (p1[good_idx,0] - p0[good_idx,0])  # Nx2\n",
    "                        d_norms = np.linalg.norm(deltas, axis=1)\n",
    "                        median_motion = float(np.median(d_norms))\n",
    "                    else:\n",
    "                        median_motion = np.inf\n",
    "\n",
    "                    # If median motion small -> consider it jitter; use small alpha smoothing\n",
    "                    if median_motion < JITTER_THRESH_PX:\n",
    "                        alpha = EMA_ALPHA_STATIC\n",
    "                    else:\n",
    "                        alpha = EMA_ALPHA_MOVING\n",
    "\n",
    "                    # Update positions: for tracked points, apply EMA blending; for lost points keep previous\n",
    "                    if p1 is not None:\n",
    "                        for i_idx in range(len(p0)):\n",
    "                            if st[i_idx] == 1:\n",
    "                                new_pt = p1[i_idx,0]\n",
    "                                sampled_points[i_idx] = (1.0 - alpha) * sampled_points[i_idx] + alpha * new_pt\n",
    "                            else:\n",
    "                                # leave as is (or optionally snap to nearest later)\n",
    "                                pass\n",
    "\n",
    "                # If too many points outside the current mask, attempt a robust registration (affine) to pull cloud back\n",
    "                inside_mask_flags = []\n",
    "                ys_mask, xs_mask = np.where(mask_full > 0)\n",
    "                mask_points = None\n",
    "                if len(xs_mask) > 0:\n",
    "                    mask_points = np.column_stack([xs_mask, ys_mask]).astype(np.float32)\n",
    "                for pt in sampled_points:\n",
    "                    x_pt = int(round(pt[0])); y_pt = int(round(pt[1]))\n",
    "                    inside_mask_flags.append(0 <= x_pt < CAM_W and 0 <= y_pt < CAM_H and mask_full[y_pt, x_pt] > 0)\n",
    "                inside_count = sum(1 for v in inside_mask_flags if v)\n",
    "                if inside_count < max(3, sampled_points.shape[0]//2) and mask_points is not None and mask_points.shape[0] > 0:\n",
    "                    # Build simple nearest correspondence between current sampled_points and mask_points (subsample masks for speed)\n",
    "                    max_target = 3000\n",
    "                    if mask_points.shape[0] > max_target:\n",
    "                        idxs_t = rng.choice(len(mask_points), size=max_target, replace=False)\n",
    "                        pts_target_sub = mask_points[idxs_t]\n",
    "                    else:\n",
    "                        pts_target_sub = mask_points\n",
    "                    # brute-force nearest neighbor matching\n",
    "                    src = sampled_points.copy()\n",
    "                    matched_src = []\n",
    "                    matched_dst = []\n",
    "                    for p in src:\n",
    "                        d2 = np.sum((pts_target_sub - p.reshape(1,2))**2, axis=1)\n",
    "                        idx_min = int(np.argmin(d2))\n",
    "                        matched_src.append(p)\n",
    "                        matched_dst.append(pts_target_sub[idx_min])\n",
    "                    matched_src = np.array(matched_src, dtype=np.float32)\n",
    "                    matched_dst = np.array(matched_dst, dtype=np.float32)\n",
    "                    if matched_src.shape[0] >= 3:\n",
    "                        M, inliers = cv2.estimateAffinePartial2D(matched_src, matched_dst, method=cv2.RANSAC,\n",
    "                                                                 ransacReprojThreshold=5.0, maxIters=2000)\n",
    "                        if M is not None:\n",
    "                            pts_h = np.hstack([sampled_points, np.ones((sampled_points.shape[0],1), dtype=np.float32)])\n",
    "                            transformed = (M @ pts_h.T).T\n",
    "                            # blend to avoid sudden jumps (REG_ALPHA)\n",
    "                            sampled_points = (1.0 - REG_ALPHA) * sampled_points + REG_ALPHA * transformed.astype(np.float32)\n",
    "\n",
    "                # Ensure points remain inside mask; if not, snap to nearest mask pixel (this is expensive but used rarely)\n",
    "                if mask_points is not None and mask_points.shape[0] > 0:\n",
    "                    for i_pt, pt in enumerate(sampled_points):\n",
    "                        x_pt = int(round(pt[0])); y_pt = int(round(pt[1]))\n",
    "                        if not (0 <= x_pt < CAM_W and 0 <= y_pt < CAM_H and mask_full[y_pt, x_pt] > 0):\n",
    "                            # nearest mask pixel brute force\n",
    "                            d2 = (mask_points[:,0] - pt[0])**2 + (mask_points[:,1] - pt[1])**2\n",
    "                            idxn = int(np.argmin(d2))\n",
    "                            sampled_points[i_pt] = mask_points[idxn].astype(np.float32)\n",
    "\n",
    "                prev_gray = curr_gray.copy()\n",
    "\n",
    "            # Visualization: draw sampled_points on bbox_view and color_only\n",
    "            if sampled_points is not None and sampled_points.shape[0] > 0:\n",
    "                for (px,py) in sampled_points.astype(np.int32):\n",
    "                    cv2.circle(bbox_view, (int(px), int(py)), 4, (0,255,0), -1)\n",
    "                color_only = cv2.bitwise_and(full, full, mask=mask_full)\n",
    "                for (px,py) in sampled_points.astype(np.int32):\n",
    "                    cv2.circle(color_only, (int(px), int(py)), 4, (0,255,0), -1)\n",
    "            else:\n",
    "                color_only = cv2.bitwise_and(full, full, mask=mask_full)\n",
    "\n",
    "            # draw bbox/contour/centroid\n",
    "            cnts_full, _ = cv2.findContours(mask_full, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            if cnts_full:\n",
    "                c_full = max(cnts_full, key=cv2.contourArea)\n",
    "                area_full = cv2.contourArea(c_full)\n",
    "                if area_full > 0:\n",
    "                    x,y,w,h = cv2.boundingRect(c_full)\n",
    "                    M = cv2.moments(c_full)\n",
    "                    if M[\"m00\"] != 0:\n",
    "                        cx = int(M[\"m10\"]/M[\"m00\"]); cy = int(M[\"m01\"]/M[\"m00\"])\n",
    "                    else:\n",
    "                        cx,cy = x + w//2, y + h//2\n",
    "                    cv2.drawContours(bbox_view, [c_full], -1, (0,255,255), 2)\n",
    "                    cv2.rectangle(bbox_view, (x,y), (x+w, y+h), (0,255,0), 3)\n",
    "                    cv2.circle(bbox_view, (cx,cy), 6, (0,0,255), -1)\n",
    "                    cv2.putText(bbox_view, f\"HSV={selected_hsv}\", (x, max(30, y-10)),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,255,255), 2, cv2.LINE_AA)\n",
    "\n",
    "        # combine three panels\n",
    "        combined = np.hstack([raw_view, bbox_view, color_only])\n",
    "        _combined_h, _combined_w = combined.shape[0], combined.shape[1]\n",
    "\n",
    "        # scale to fit 720px height\n",
    "        target_h = 720\n",
    "        scale = target_h / _combined_h\n",
    "        display_w = int(_combined_w * scale)\n",
    "        display_h = target_h\n",
    "        display = cv2.resize(combined, (display_w, display_h), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "        # update mapping globals used for clicks\n",
    "        _display_w, _display_h = display_w, display_h\n",
    "\n",
    "        # update SAMPLE_COUNT from trackbar\n",
    "        SAMPLE_COUNT = cv2.getTrackbarPos(\"NumPoints\", WINDOW)\n",
    "\n",
    "        hint = f\"Click to pick color (regenerates points) | Q to quit | NumPoints={SAMPLE_COUNT}\"\n",
    "        if color_selected and selected_hsv is not None:\n",
    "            hint = f\"{hint}    Selected HSV={selected_hsv}\"\n",
    "        cv2.putText(display, hint, (10,30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2, cv2.LINE_AA)\n",
    "\n",
    "        cv2.imshow(WINDOW, display)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "finally:\n",
    "    pipe.stop()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "srs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
